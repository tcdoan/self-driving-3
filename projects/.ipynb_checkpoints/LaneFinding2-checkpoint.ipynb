{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Advanced Lane Finding\n",
    "\n",
    "\n",
    "### 1. Tips and Tricks for the Project\n",
    "\n",
    "##### Camera Calibration\n",
    "- Set chessboard size to 9x6 for the project instead of 8x6 to be consistent with project calibration images\n",
    "\n",
    "##### Do curvature values make sense?\n",
    "- Perform a good check on whether or not  perspective transform worked as expected\n",
    "- Check on whether conversion from pixel space to world space was correct \n",
    "- Check that the radius of curvature is roughly consistent with reality\n",
    "\n",
    "Here is an image from Google maps of where the project video was made (just northwest of the Udacity office). \n",
    "\n",
    "- Here is the circle to osculate the first left curve in the project video. \n",
    "- This is a very rough estimate, but, the radius of that circle is approximately 1 km. \n",
    "- Won't need to tune algorithm to report exactly a radius of 1 km in the project...\n",
    "    - but `if reporting 10 km or 0.1 km then somethinng is wrong` with calculations.\n",
    "   \n",
    "!['left_curve_radius'](left_curve_radius.png)\n",
    "\n",
    "##### Offset\n",
    "- The camera is mounted at the center of the car, such that the lane center is the midpoint at the bottom of the image between the two detected lines. \n",
    "- The offset of the lane center from the center of the image (converted from pixels to meters) is your distance from the center of the lane.\n",
    "\n",
    "\n",
    "##### Tracking \n",
    "- After  pipeline is tuned on test images, run on a video stream, just like in the first project.\n",
    "- In this case, however, we're going to keep track of things like where last several detections of the lane lines were and what the curvature was, so we can properly treat new detections.\n",
    "- To do this, it's useful to define a `Line` class to keep track of all the interesting parameters we measure from frame to frame.\n",
    "\n",
    "```python\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n",
    "```\n",
    "\n",
    "- Create instances of the Line() class for the left and right lane lines to keep track of recent detections and to perform sanity checks.\n",
    "\n",
    "\n",
    "##### Sanity Check \n",
    "\n",
    "- Check that the detection makes sense. To confirm that detected lane lines are real, consider:\n",
    "  - Checking that they have similar curvature\n",
    "  - Checking that they are separated by approximately the right distance horizontally\n",
    "  - Checking that they are roughly parallel\n",
    "  \n",
    "##### Look-Ahead Filter\n",
    "\n",
    "- Once we've found the lane lines in one frame of video, and reasonably confident they are actually the real lines...\n",
    "    - we don't need to search blindly in the next frame. \n",
    "    - we can simply search within a window around the previous detection.\n",
    "\n",
    "- For example, if we fit a polynomial, then for each y position, we have an x position that represents the lane center from the last frame.\n",
    "- Search for the new line within +/- some margin around the old line center.\n",
    "  - Aka Search from Prior...\n",
    "  \n",
    "- Then check that new line detections makes sense (i.e. expected curvature, separation, and slope).\n",
    "\n",
    "\n",
    "##### Reset\n",
    "- If your sanity checks reveal that the lane lines you've detected are problematic for some reason, \n",
    "  - Assume it was a bad or difficult frame of video, retain the previous positions from the frame prior and step to the next frame to search again. \n",
    "- If we lose the lines for several frames in a row, \n",
    "   - Start searching from scratch using a histogram and sliding window, or another method, to re-establish measurement.\n",
    "\n",
    "##### Smoothing\n",
    "- Even when everything is working, line detections might jump around from frame to frame a bit and it can be preferable to smooth over the last n frames of video to obtain a cleaner result.\n",
    "\n",
    "- Each time we get a new high-confidence measurement, we can append it to the list of recent measurements and then take an average over n past measurements to obtain the lane position we want to draw onto the image.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd3]",
   "language": "python",
   "name": "conda-env-carnd3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
