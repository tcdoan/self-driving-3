{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward network to classify traffic signs using Keras\n",
    "\n",
    "- Set the first layer to a Flatten() layer with input_shape set to (32, 32, 3).\n",
    "- Set the second layer to a Dense() layer with an output width of 128.\n",
    "- Use a ReLU activation function after the second layer.\n",
    "- Set output layer width to 5, because for this data set there are only 5 classes.\n",
    "- Use a softmax activation function after the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.2441 - acc: 0.3625 - val_loss: 0.8747 - val_acc: 0.6500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.9460 - acc: 0.6500 - val_loss: 0.5806 - val_acc: 0.8500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 194us/step - loss: 0.6182 - acc: 0.7000 - val_loss: 0.5649 - val_acc: 0.7500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.8161932826042175\n",
      "Test accuracy: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open('small_test_traffic.p', mode='rb') as testf:\n",
    "    test_data = pickle.load(testf)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5)\n",
    "\n",
    "X_test,  y_test  = test_data['features'], test_data['labels']\n",
    "X_test2 = np.array(X_test / 255.0 - 0.5)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dense(5))\n",
    "# model.add(Activation('softmax'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics  =['accuracy'])\n",
    "history = model.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "- Build from the previous network.\n",
    "- Add a convolutional layer with 32 filters, a 3x3 kernel, \n",
    "    - and valid padding before the flatten layer.\n",
    "- Add a ReLU activation after the convolutional layer.\n",
    "- Train for 3 epochs again, should be able to get over 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 1.4374 - acc: 0.5250 - val_loss: 0.8386 - val_acc: 0.7000\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8874 - acc: 0.7000 - val_loss: 0.5858 - val_acc: 0.8500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5166 - acc: 0.8250 - val_loss: 0.3970 - val_acc: 0.8500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.6180269718170166\n",
      "Test accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), input_shape=(32, 32, 3)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics  =['accuracy'])\n",
    "history = model2.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model2.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car2]",
   "language": "python",
   "name": "conda-env-car2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
