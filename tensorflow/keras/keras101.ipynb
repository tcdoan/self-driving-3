{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward network to classify traffic signs using Keras\n",
    "\n",
    "- Set the first layer to a Flatten() layer with input_shape set to (32, 32, 3).\n",
    "- Set the second layer to a Dense() layer with an output width of 128.\n",
    "- Use a ReLU activation function after the second layer.\n",
    "- Set output layer width to 5, because for this data set there are only 5 classes.\n",
    "- Use a softmax activation function after the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.2441 - acc: 0.3625 - val_loss: 0.8747 - val_acc: 0.6500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 221us/step - loss: 0.9460 - acc: 0.6500 - val_loss: 0.5806 - val_acc: 0.8500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 194us/step - loss: 0.6182 - acc: 0.7000 - val_loss: 0.5649 - val_acc: 0.7500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.8161932826042175\n",
      "Test accuracy: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open('small_test_traffic.p', mode='rb') as testf:\n",
    "    test_data = pickle.load(testf)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5)\n",
    "\n",
    "X_test,  y_test  = test_data['features'], test_data['labels']\n",
    "X_test2 = np.array(X_test / 255.0 - 0.5)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dense(5))\n",
    "# model.add(Activation('softmax'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics  =['accuracy'])\n",
    "history = model.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "- Build from the previous network.\n",
    "- Add a convolutional layer with 32 filters, a 3x3 kernel, \n",
    "    - and valid padding before the flatten layer.\n",
    "- Add a ReLU activation after the convolutional layer.\n",
    "- Train for 3 epochs again, should be able to get over 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 1.2890 - acc: 0.3750 - val_loss: 0.7974 - val_acc: 0.7500\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8118 - acc: 0.6250 - val_loss: 0.9243 - val_acc: 0.7000\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9469 - acc: 0.5750 - val_loss: 0.5656 - val_acc: 0.8500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.8366739153862\n",
      "Test accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), activation='relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model2.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics  =['accuracy'])\n",
    "history = model2.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model2.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "\n",
    "- Build from the previous network\n",
    "- Add a 2x2 max pooling layer immediately following your convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 1.3032 - acc: 0.3125 - val_loss: 0.9203 - val_acc: 0.6000\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 705us/step - loss: 0.9537 - acc: 0.5750 - val_loss: 0.8471 - val_acc: 0.6500\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.8568 - acc: 0.6375 - val_loss: 0.6531 - val_acc: 0.8500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.842922031879425\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(5, activation='softmax'))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model3.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics  =['accuracy'])\n",
    "history = model3.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model3.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "- Build from the previous network.\n",
    "- Add a dropout layer after the pooling layer. \n",
    "    - Set the dropout rate to 50%.\n",
    "- Make sure to note from the documentation above that the rate specified for dropout in Keras is the opposite of TensorFlow.\n",
    "    - TensorFlow uses the probability to keep nodes. Keras uses the probability to drop them.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.4460 - acc: 0.3125 - val_loss: 0.9682 - val_acc: 0.7000\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 795us/step - loss: 1.0108 - acc: 0.5625 - val_loss: 0.7567 - val_acc: 0.7000\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 715us/step - loss: 0.8204 - acc: 0.7000 - val_loss: 0.6232 - val_acc: 0.7500\n",
      "----------------------------------------------------------------------\n",
      "Test loss: 0.7863947153091431\n",
      "Test accuracy: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, (3,3), input_shape=(32, 32, 3), activation='relu'))\n",
    "model4.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Before or after Flatten layer?\n",
    "model4.add(Flatten())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(5, activation='softmax'))\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "y_test_onehot = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "model4.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics  =['accuracy'])\n",
    "history = model4.fit(X_normalized, \n",
    "                    y_one_hot, epochs=3,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "score = model4.evaluate(X_test2, y_test_onehot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15*15*16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car2]",
   "language": "python",
   "name": "conda-env-car2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
